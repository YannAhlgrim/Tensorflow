{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Activation\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import TensorBoard\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "MODELS_DIR = os.path.abspath(\"C:/Projects/tensorflow/models\")\n",
    "MODEL_FILE_PATH = os.path.join(MODELS_DIR, \"cifar10_model.h5\")\n",
    "FULL_MODEL_FILE_PATH = os.path.join(MODELS_DIR, \"full_cifar10_model\")\n",
    "LOGS_DIR = os.path.abspath(\"C:/Projects/tensorflow/logs\")\n",
    "MODEL_LOGS_DIR = os.path.join(LOGS_DIR, \"cifar10_logs\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(num_classes: int) -> tuple[tuple[np.ndarray, np.ndarray], tuple[np.ndarray, np.ndarray], tuple[np.ndarray, np.ndarray]]:\n",
    "    (x_train, y_train), (x_val_, y_val_) = cifar10.load_data()\n",
    "    x_train = x_train.astype(np.float32)\n",
    "    x_val_ = x_val_.astype(np.float32)\n",
    "    x_val, x_test, y_val, y_test = train_test_split(x_val_, y_val_, test_size=0.66)\n",
    "    x_test = x_test.astype(np.float32)\n",
    "    \n",
    "    # normalize\n",
    "    x_train = x_train/255.0\n",
    "    x_val = x_val/255.0\n",
    "    x_test = x_test/255.0\n",
    "\n",
    "    # Data Augmentation\n",
    "    augment_size = 5_000\n",
    "    image_gen = ImageDataGenerator(\n",
    "        rotation_range=5,\n",
    "        zoom_range=0.05,\n",
    "        width_shift_range=0.08,\n",
    "        height_shift_range=0.08\n",
    "    )\n",
    "    image_gen.fit(x_train, augment=True)\n",
    "    rndm_idxs = np.random.randint(low=x_train.shape[0],high=None, size=augment_size)\n",
    "    x_augmented = x_train[rndm_idxs].copy()\n",
    "    y_augmented = y_train[rndm_idxs].copy()\n",
    "    x_augmented = image_gen.flow(x_augmented, np.zeros(augment_size), batch_size=augment_size, shuffle=False).next()[0]\n",
    "    x_train = np.concatenate((x_train, x_augmented))\n",
    "    y_train = np.concatenate((y_train, y_augmented))\n",
    "    \n",
    "    y_train = to_categorical(y_train, num_classes=num_classes, dtype=np.float32)\n",
    "    y_val = to_categorical(y_val, num_classes=num_classes, dtype=np.float32)\n",
    "    y_test = to_categorical(y_test, num_classes=num_classes, dtype=np.float32)\n",
    "    print (f\"x shape: {x_train.shape}   y shape: {y_train.shape}\")\n",
    "    return (x_train, y_train), (x_val, y_val), (x_test, y_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: (55000, 32, 32, 3)   y shape: (55000, 10)\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "img_shape = (32, 32, 3)\n",
    "(x_train, y_train), (x_val, y_val), (x_test, y_test) = get_dataset(num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(img_shape : tuple[int,int,int], num_classes: int, filters1: int, filters2: int,\n",
    "                filters3: int,kernel1: int, kernel2: int, kernel3: int, dense_layer: int,\n",
    "                learning_rate: float, optimizer: tf.keras.optimizers.Optimizer) -> Model:\n",
    "    \n",
    "    img_input = Input(img_shape)\n",
    "    x = Conv2D(filters=filters1, kernel_size=kernel1, padding = \"same\")(img_input)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(filters=filters2, kernel_size=kernel2)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    x = Conv2D(filters=filters3, kernel_size=kernel3)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "     \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(units=dense_layer)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dense(units=num_classes)(x)\n",
    "    y_pred = Activation(\"softmax\")(x)\n",
    "    \n",
    "    model = Model(\n",
    "        inputs=[img_input],\n",
    "        outputs=[y_pred]\n",
    "    )\n",
    "    \n",
    "    model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=optimizer(learning_rate=learning_rate),\n",
    "              metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Model with GridSearch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"filters1\": [32], \"filters2\": [32,64], \"filters3\": [64, 128],\n",
    "    \"kernel1\": [3,5], \"kernel2\": [3,5], \"kernel3\": [7],\n",
    "    \"dense_layer\": [512], \"learning_rate\": [0.001, 0.0005],\n",
    "    \"optimizer\": [Adam, RMSprop]\n",
    "}\n",
    "\n",
    "results = {\n",
    "    \"best_score\": -np.inf,\n",
    "    \"best_params\": {},\n",
    "    \"val_scores\": [],\n",
    "    \"params\": []\n",
    "}\n",
    "\n",
    "grid = ParameterGrid(param_grid= param_grid)\n",
    "\n",
    "for idx, param in enumerate(grid):\n",
    "    print(f\"{idx}.Combination Run:\")\n",
    "    model = build_model(img_shape=img_shape,num_classes=num_classes, **param)\n",
    "\n",
    "    model_log_dir = os.path.join(LOGS_DIR, f\"modelGrid{idx}\")\n",
    "    if os.path.exists(model_log_dir):\n",
    "        shutil.rmtree(model_log_dir)\n",
    "        os.mkdir(model_log_dir)\n",
    "        \n",
    "    tb_callback = TensorBoard(\n",
    "        log_dir=model_log_dir,\n",
    "        histogram_freq=0\n",
    "    )\n",
    "\n",
    "    history = model.fit (x=x_train, \n",
    "            y=y_train, \n",
    "            epochs=10, \n",
    "            batch_size=128, \n",
    "            verbose=1, \n",
    "            validation_data=(x_val, y_val),\n",
    "            callbacks=[tb_callback])\n",
    "    \n",
    "    #Plot Accuracy\n",
    "    scores = model.evaluate(x=x_val, y=y_val)\n",
    "    \n",
    "    results[\"val_scores\"].append(scores)\n",
    "    results[\"params\"].append(param)\n",
    "\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "best_run_idx = np.argmax(results[\"val_scores\"])\n",
    "results[\"best_score\"] = results[\"val_scores\"][best_run_idx]\n",
    "results[\"best_params\"] = results[\"params\"][best_run_idx]\n",
    "print(f\"Best score: {results['best_score']} using params: {results['best_params']} \\n\")\n",
    "\n",
    "scores = results[\"val_scores\"]\n",
    "params = results[\"params\"]\n",
    "for score, param in zip(scores, params):\n",
    "    print(f\"Score: {score} using params: {param}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Model/Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights\n",
    "model.save_weights(filepath=MODEL_FILE_PATH)\n",
    "model.save(filepath=FULL_MODEL_FILE_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Model/Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(filepath=MODEL_FILE_PATH)\n",
    "model = load_model(filepath=FULL_MODEL_FILE_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
